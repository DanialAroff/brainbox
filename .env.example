# Server Configuration
PORT=3000

# Rate Limiting Configuration
# Time window in milliseconds (default: 900000 = 15 minutes)
RATE_LIMIT_WINDOW_MS=900000
# Maximum requests per window for general endpoints (default: 100)
RATE_LIMIT_MAX_REQUESTS=100
# Maximum requests per window for expensive operations like embed/ingest (default: 20)
RATE_LIMIT_MAX_EXPENSIVE=20

# Embedding Service Configuration (LM Studio, llama.cpp, or any OpenAI-compatible API)
EMBEDDING_SERVICE_URL=http://127.0.0.1:1234/v1/embeddings
EMBED_MODEL=text-embedding-nomic-embed-text-v1.5

# ChromaDB Configuration
CHROMA_HOST=localhost
CHROMA_PORT=8000
CHROMA_SSL=false
COLLECTION_NAME=internal-faq

# FAQ Files Directory (relative to project root or absolute path)
FAQS_PATH=./data/faqs

# Chunking Strategy Configuration
# Options: 'smart' (sentence-boundary, default) or 'naive' (character-based)
# Smart chunking preserves sentence boundaries for better semantic coherence
# Naive chunking uses fixed character positions (may break sentences mid-way)
CHUNKING_STRATEGY=smart

# CORS Configuration (comma-separated allowed origins, or * for all)
CORS_ORIGIN=*
