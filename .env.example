# Server Configuration
PORT=3000

# Embedding Service Configuration (LM Studio, llama.cpp, or any OpenAI-compatible API)
EMBEDDING_SERVICE_URL=http://127.0.0.1:1234/v1/embeddings
EMBED_MODEL=text-embedding-nomic-embed-text-v1.5

# ChromaDB Configuration
CHROMA_HOST=localhost
CHROMA_PORT=8000
CHROMA_SSL=false
COLLECTION_NAME=internal-faq

# FAQ Files Directory (relative to project root or absolute path)
FAQS_PATH=./data/faqs

# CORS Configuration (comma-separated allowed origins, or * for all)
CORS_ORIGIN=*
